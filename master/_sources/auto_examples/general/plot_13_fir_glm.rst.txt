
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/general/plot_13_fir_glm.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_examples_general_plot_13_fir_glm.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_general_plot_13_fir_glm.py:


.. _tut-fnirs-fir:

GLM FIR Analysis
================

In this example we analyse data from a real multi-channel
functional near-infrared spectroscopy (fNIRS)
experiment (see :ref:`tut-fnirs-hrf-sim` for a simplified simulated
analysis). The experiment consists of three conditions:
1) tapping with the left hand,
2) tapping with the right hand, and
3) a control condition where the participant does nothing.

In this tutorial the morphology of an fNIRS response is obtained using a
Finite Impulse Response (FIR) GLM analysis.
An alternative epoching-style analysis on the same data can be
viewed in the
:ref:`waveform analysis example <tut-fnirs-group-wave>`.
See
`Luke et al (2021) <https://www.spiedigitallibrary.org/journals/neurophotonics/volume-8/issue-2/025008/Analysis-methods-for-measuring-passive-auditory-fNIRS-responses-generated-by/10.1117/1.NPh.8.2.025008.short>`_
for a comparison of the epoching and GLM FIR approaches.

This tutorial only examines the tapping with the right hand condition
to simplify explanation and minimise computation time. The reader is invited
to expand the code to also analyse the other conditions.

This GLM analysis is a wrapper over the excellent
`Nilearn GLM <http://nilearn.github.io/modules/reference.html#module-nilearn.glm>`_.

.. note::

   This is an advanced tutorial and requires knowledge of pandas and numpy.
   I plan to write some functions to make this more convenient in the future.

.. note::

   The sample rate used in this example is set to 0.5 Hz. This is done to
   ensure that the code can run on the continuous integration servers. You may
   wish to increase the sample rate by adjusting `resample` below for your
   own analysis.

.. contents:: Page contents
   :local:
   :depth: 2

.. GENERATED FROM PYTHON SOURCE LINES 48-79

.. code-block:: default

    # sphinx_gallery_thumbnail_number = 1

    # Authors: Robert Luke <mail@robertluke.net>
    #
    # License: BSD (3-clause)


    # Import common libraries
    import numpy as np
    import pandas as pd

    # Import MNE processing
    from mne.preprocessing.nirs import optical_density, beer_lambert_law

    # Import MNE-NIRS processing
    from mne_nirs.statistics import run_GLM
    from mne_nirs.experimental_design import make_first_level_design_matrix
    from mne_nirs.statistics import glm_region_of_interest, statsmodels_to_results
    from mne_nirs.datasets import fnirs_motor_group
    from mne_nirs.channels import get_short_channels, get_long_channels

    # Import MNE-BIDS processing
    from mne_bids import BIDSPath, read_raw_bids

    # Import StatsModels
    import statsmodels.formula.api as smf

    # Import Plotting Library
    import matplotlib.pyplot as plt









.. GENERATED FROM PYTHON SOURCE LINES 80-89

Define FIR analysis
---------------------------------------------------------------------

This code runs a FIR GLM analysis.
It fits a FIR for each sample from the onset of a trigger.
We specify here that 10 FIR delays should be used.
This results in values being estimated for 10 `delay` steps.
Due to the chosen sample rate of 0.5 Hz, these delays
correspond to 0, 2, 4... seconds from the onset of the stimulus.

.. GENERATED FROM PYTHON SOURCE LINES 89-131

.. code-block:: default


    def analysis(fname, ID):

        raw_intensity = read_raw_bids(bids_path=fname, verbose=False)

        # Convert signal to haemoglobin and just keep hbo
        raw_od = optical_density(raw_intensity)
        raw_haemo = beer_lambert_law(raw_od)
        raw_haemo.resample(0.5, npad="auto")

        # Cut out just the short channels for creating a GLM regressor
        short_chans = get_short_channels(raw_haemo)
        raw_haemo = get_long_channels(raw_haemo)

        # Create a design matrix
        design_matrix = make_first_level_design_matrix(raw_haemo,
                                                       hrf_model='fir',
                                                       stim_dur=1.0,
                                                       fir_delays=range(10),
                                                       drift_model='cosine',
                                                       high_pass=0.01,
                                                       oversampling=1)
        # Add short channels as regressor in GLM
        for chan in range(len(short_chans.ch_names)):
            design_matrix[f"short_{chan}"] = short_chans.get_data(chan).T

        # Run GLM
        glm_est = run_GLM(raw_haemo, design_matrix)

        # Create a single ROI that includes all channels for example
        rois = dict(AllChannels=range(len(raw_haemo.ch_names)))
        # Compute output metrics by ROI
        df_ind = pd.DataFrame()
        for idx, col in enumerate(design_matrix.columns):
            df_ind = df_ind.append(glm_region_of_interest(glm_est, rois, idx, col))

        df_ind["ID"] = ID
        df_ind["theta"] = [t * 1.e6 for t in df_ind["theta"]]

        return df_ind, raw_haemo, design_matrix









.. GENERATED FROM PYTHON SOURCE LINES 132-138

Run analysis
---------------------------------------------------------------------

The analysis is run on each individual subject measurement.
The individual results are then appended to a dataframe for
group-level analysis below.

.. GENERATED FROM PYTHON SOURCE LINES 138-154

.. code-block:: default


    df = pd.DataFrame()

    for sub in range(1, 6):  # Loop from first to fifth subject
        ID = '%02d' % sub  # Tidy the subject name

        # Create path to file based on experiment info
        bids_path = BIDSPath(subject=ID, task="tapping",
                             root=fnirs_motor_group.data_path(),
                             datatype="nirs", suffix="nirs", extension=".snirf")

        df_individual, raw, dm = analysis(bids_path, ID)

        df = df.append(df_individual)






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Loading /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-01/nirs/sub-01_task-tapping_nirs.snirf
    Reading events from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-01/nirs/sub-01_task-tapping_events.tsv.
    Reading channel info from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-01/nirs/sub-01_task-tapping_channels.tsv.
    Reading 0 ... 23238  =      0.000 ...  2974.464 secs...
    Loading /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-02/nirs/sub-02_task-tapping_nirs.snirf
    Reading events from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-02/nirs/sub-02_task-tapping_events.tsv.
    Reading channel info from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-02/nirs/sub-02_task-tapping_channels.tsv.
    Reading 0 ... 18877  =      0.000 ...  2416.256 secs...
    Loading /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-03/nirs/sub-03_task-tapping_nirs.snirf
    Reading events from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-03/nirs/sub-03_task-tapping_events.tsv.
    Reading channel info from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-03/nirs/sub-03_task-tapping_channels.tsv.
    Reading 0 ... 18874  =      0.000 ...  2415.872 secs...
    Loading /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-04/nirs/sub-04_task-tapping_nirs.snirf
    Reading events from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-04/nirs/sub-04_task-tapping_events.tsv.
    Reading channel info from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-04/nirs/sub-04_task-tapping_channels.tsv.
    Reading 0 ... 23120  =      0.000 ...  2959.360 secs...
    Loading /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-05/nirs/sub-05_task-tapping_nirs.snirf
    Reading events from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-05/nirs/sub-05_task-tapping_events.tsv.
    Reading channel info from /home/runner/mne_data/MNE-fNIRS-motor-group-data/sub-05/nirs/sub-05_task-tapping_channels.tsv.
    Reading 0 ... 23006  =      0.000 ...  2944.768 secs...




.. GENERATED FROM PYTHON SOURCE LINES 155-161

Tidy the dataframe
---------------------------------------------------------------------

For simplicity we only examine the data from the right hand
tapping condition. The code below retains only the relevant information
from the dataframe and design matrix for the following statistical analysis.

.. GENERATED FROM PYTHON SOURCE LINES 161-181

.. code-block:: default


    # Keep only tapping and FIR delay information in the dataframe
    # I.e., for this example we are not interest in the drift coefficients,
    # short channel information, or control conditions.
    df["isTapping"] = ["Tapping/Right" in n for n in df["Condition"]]
    df["isDelay"] = ["delay" in n for n in df["Condition"]]
    df = df.query("isDelay in [True]")
    df = df.query("isTapping in [True]")
    # Make a new column that stores the condition name for tidier model below
    df.loc[df["isTapping"] == True, "TidyCond"] = "Tapping"
    # Finally, extract the FIR delay in to its own column in data frame
    df.loc[:, "delay"] = [n.split('_')[2] for n in df.Condition]

    # To simplify this example we will only look at the right hand tapping
    # condition so we now remove the left tapping conditions from the
    # design matrix and GLM results
    dm_cols_not_left = np.where(["Right" in c for c in dm.columns])[0]
    dm = dm[[dm.columns[i] for i in dm_cols_not_left]]









.. GENERATED FROM PYTHON SOURCE LINES 182-188

Run group-level model
---------------------------------------------------------------------

A linear mixed effects (LME) model is used to determine the effect
of FIR delay for each chromophore on the evoked response with participant
(ID) as a random variable.

.. GENERATED FROM PYTHON SOURCE LINES 188-196

.. code-block:: default


    lme = smf.mixedlm('theta ~ -1 + delay:TidyCond:Chroma', df,
                      groups=df["ID"]).fit()

    # The model is summarised below, and is not displayed here.
    # You can display the model output using: lme.summary()









.. GENERATED FROM PYTHON SOURCE LINES 197-204

Summarise group-level findings
---------------------------------------------------------------------

Next the values from the model above are extracted into a dataframe for
more convenient analysis below.
A subset of the results is displayed, illustrating the estimated coefficients
for oxyhaemoglobin (HbO) for the right hand tapping condition.

.. GENERATED FROM PYTHON SOURCE LINES 204-213

.. code-block:: default


    # Create a dataframe from LME model for plotting below
    df_sum = statsmodels_to_results(lme)
    df_sum["delay"] = [int(n) for n in df_sum["delay"]]
    df_sum = df_sum.sort_values('delay')

    # Print the result for the oxyhaemoglobin data in the tapping condition
    df_sum.query("TidyCond in ['Tapping']").query("Chroma in ['hbo']")






.. raw:: html

    <div class="output_subarea output_html rendered_html output_result">
    <div>
    <style scoped>
        .dataframe tbody tr th:only-of-type {
            vertical-align: middle;
        }

        .dataframe tbody tr th {
            vertical-align: top;
        }

        .dataframe thead th {
            text-align: right;
        }
    </style>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Coef.</th>
          <th>Std.Err.</th>
          <th>z</th>
          <th>P&gt;|z|</th>
          <th>[0.025</th>
          <th>0.975]</th>
          <th>delay</th>
          <th>TidyCond</th>
          <th>Chroma</th>
          <th>Significant</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>delay[0]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>0.479145</td>
          <td>0.967164</td>
          <td>0.495413</td>
          <td>6.203089e-01</td>
          <td>-1.416461</td>
          <td>2.374752</td>
          <td>0</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>False</td>
        </tr>
        <tr>
          <th>delay[1]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>2.103731</td>
          <td>0.967164</td>
          <td>2.175155</td>
          <td>2.961850e-02</td>
          <td>0.208125</td>
          <td>3.999338</td>
          <td>1</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>True</td>
        </tr>
        <tr>
          <th>delay[2]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>4.896282</td>
          <td>0.967164</td>
          <td>5.062515</td>
          <td>4.137612e-07</td>
          <td>3.000675</td>
          <td>6.791888</td>
          <td>2</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>True</td>
        </tr>
        <tr>
          <th>delay[3]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>6.734765</td>
          <td>0.967164</td>
          <td>6.963417</td>
          <td>3.321171e-12</td>
          <td>4.839159</td>
          <td>8.630372</td>
          <td>3</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>True</td>
        </tr>
        <tr>
          <th>delay[4]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>6.821831</td>
          <td>0.967164</td>
          <td>7.053438</td>
          <td>1.745498e-12</td>
          <td>4.926224</td>
          <td>8.717437</td>
          <td>4</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>True</td>
        </tr>
        <tr>
          <th>delay[5]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>4.189877</td>
          <td>0.967164</td>
          <td>4.332128</td>
          <td>1.476753e-05</td>
          <td>2.294271</td>
          <td>6.085484</td>
          <td>5</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>True</td>
        </tr>
        <tr>
          <th>delay[6]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>1.629857</td>
          <td>0.967164</td>
          <td>1.685192</td>
          <td>9.195148e-02</td>
          <td>-0.265749</td>
          <td>3.525463</td>
          <td>6</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>False</td>
        </tr>
        <tr>
          <th>delay[7]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>0.470915</td>
          <td>0.967164</td>
          <td>0.486903</td>
          <td>6.263270e-01</td>
          <td>-1.424691</td>
          <td>2.366521</td>
          <td>7</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>False</td>
        </tr>
        <tr>
          <th>delay[8]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>-0.004232</td>
          <td>0.967164</td>
          <td>-0.004376</td>
          <td>9.965086e-01</td>
          <td>-1.899839</td>
          <td>1.891374</td>
          <td>8</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>False</td>
        </tr>
        <tr>
          <th>delay[9]:TidyCond[Tapping]:Chroma[hbo]</th>
          <td>-0.085403</td>
          <td>0.967164</td>
          <td>-0.088303</td>
          <td>9.296361e-01</td>
          <td>-1.98101</td>
          <td>1.810203</td>
          <td>9</td>
          <td>Tapping</td>
          <td>hbo</td>
          <td>False</td>
        </tr>
      </tbody>
    </table>
    </div>
    </div>
    <br />
    <br />

.. GENERATED FROM PYTHON SOURCE LINES 214-218

Note in the output above that there are 10 FIR delays.
A coefficient estimate has been calculated for each delay.
These coefficients must be multiplied by the FIR function to obtain the
morphology of the fNIRS response.

.. GENERATED FROM PYTHON SOURCE LINES 220-228

Plot the response from a single condition
---------------------------------------------------------------------

Finally we create a plot with two facets.
The first facet illustrates the estimated amplitude of each FIR component
for the right hand tapping condition for the oxyhaemoglobin data.
The second facet illustrates the overall estimated response for each
chromophore and is calculated by summing all the individual FIR components.

.. GENERATED FROM PYTHON SOURCE LINES 228-268

.. code-block:: default


    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))

    # Extract design matrix columns that correspond to the condition of interest
    dm_cond_idxs = np.where(["Tapping" in n for n in dm.columns])[0]
    dm_cond = dm[[dm.columns[i] for i in dm_cond_idxs]]

    # Extract the corresponding estimates from the lme dataframe for hbo
    df_hbo = df_sum.query("TidyCond in ['Tapping']").query("Chroma in ['hbo']")
    vals_hbo = [float(v) for v in df_hbo["Coef."]]
    dm_cond_scaled_hbo = dm_cond * vals_hbo

    # Extract the corresponding estimates from the lme dataframe for hbr
    df_hbr = df_sum.query("TidyCond in ['Tapping']").query("Chroma in ['hbr']")
    vals_hbr = [float(v) for v in df_hbr["Coef."]]
    dm_cond_scaled_hbr = dm_cond * vals_hbr

    # Extract the time scale for plotting.
    # Set time zero to be the onset of the finger tapping.
    index_values = dm_cond_scaled_hbo.index - np.ceil(raw.annotations.onset[1])

    # Plot the result
    axes[0].plot(index_values, dm_cond_scaled_hbo)
    axes[1].plot(index_values, np.sum(dm_cond_scaled_hbo, axis=1), 'r')
    axes[1].plot(index_values, np.sum(dm_cond_scaled_hbr, axis=1), 'b')

    # Format the plot
    axes[0].set_xlim(-5, 30)
    axes[1].set_xlim(-5, 30)
    axes[0].set_ylim(-5, 8)
    axes[1].set_ylim(-5, 8)
    axes[0].set_title("FIR Components (Tapping/Right)")
    axes[1].set_title("Evoked Response (Tapping/Right)")
    axes[0].set_ylabel("Oyxhaemoglobin (ΔμMol)")
    axes[1].set_ylabel("Haemoglobin (ΔμMol)")
    axes[1].legend(["Oyxhaemoglobin", "Deoyxhaemoglobin"])
    axes[0].set_xlabel("Time (s)")
    axes[1].set_xlabel("Time (s)")





.. image-sg:: /auto_examples/general/images/sphx_glr_plot_13_fir_glm_001.png
   :alt: FIR Components (Tapping/Right), Evoked Response (Tapping/Right)
   :srcset: /auto_examples/general/images/sphx_glr_plot_13_fir_glm_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Text(0.5, 47.7222222222222, 'Time (s)')



.. GENERATED FROM PYTHON SOURCE LINES 269-272

Plot the response with confidence intervals
---------------------------------------------------------------------


.. GENERATED FROM PYTHON SOURCE LINES 272-304

.. code-block:: default


    # We can also extract the 95% confidence intervals of the estimates too
    l95_hbo = [float(v) for v in df_hbo["[0.025"]]  # lower estimate
    u95_hbo = [float(v) for v in df_hbo["0.975]"]]  # upper estimate
    dm_cond_scaled_hbo_l95 = dm_cond * l95_hbo
    dm_cond_scaled_hbo_u95 = dm_cond * u95_hbo
    l95_hbr = [float(v) for v in df_hbr["[0.025"]]  # lower estimate
    u95_hbr = [float(v) for v in df_hbr["0.975]"]]  # upper estimate
    dm_cond_scaled_hbr_l95 = dm_cond * l95_hbr
    dm_cond_scaled_hbr_u95 = dm_cond * u95_hbr

    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(7, 7))

    # Plot the result
    axes.plot(index_values, np.sum(dm_cond_scaled_hbo, axis=1), 'r')
    axes.plot(index_values, np.sum(dm_cond_scaled_hbr, axis=1), 'b')
    axes.fill_between(index_values,
                         np.sum(dm_cond_scaled_hbo_l95, axis=1),
                         np.sum(dm_cond_scaled_hbo_u95, axis=1),
                         facecolor='red', alpha=0.25)
    axes.fill_between(index_values,
                         np.sum(dm_cond_scaled_hbr_l95, axis=1),
                         np.sum(dm_cond_scaled_hbr_u95, axis=1),
                         facecolor='blue', alpha=0.25)

    # Format the plot
    axes.set_xlim(-5, 30)
    axes.set_ylim(-7, 10)
    axes.set_title("Evoked Response (Tapping/Right)")
    axes.set_ylabel("Haemoglobin (ΔμMol)")
    axes.legend(["Oyxhaemoglobin", "Deoyxhaemoglobin"])
    axes.set_xlabel("Time (s)")



.. image-sg:: /auto_examples/general/images/sphx_glr_plot_13_fir_glm_002.png
   :alt: Evoked Response (Tapping/Right)
   :srcset: /auto_examples/general/images/sphx_glr_plot_13_fir_glm_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    Text(0.5, 47.7222222222222, 'Time (s)')




.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  16.341 seconds)

**Estimated memory usage:**  63 MB


.. _sphx_glr_download_auto_examples_general_plot_13_fir_glm.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_13_fir_glm.py <plot_13_fir_glm.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_13_fir_glm.ipynb <plot_13_fir_glm.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
